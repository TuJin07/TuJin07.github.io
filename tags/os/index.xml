<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>OS on 荼锦</title>
        <link>https://TuJin07.github.io/tags/os/</link>
        <description>Recent content in OS on 荼锦</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sun, 27 Nov 2022 21:07:47 +0800</lastBuildDate><atom:link href="https://TuJin07.github.io/tags/os/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>操作系统课程总结</title>
        <link>https://TuJin07.github.io/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/</link>
        <pubDate>Sun, 27 Nov 2022 21:07:47 +0800</pubDate>
        
        <guid>https://TuJin07.github.io/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/</guid>
        <description>&lt;img src="https://TuJin07.github.io/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/cover.jpeg" alt="Featured image of post 操作系统课程总结" /&gt;&lt;h1 id=&#34;操作系统基础总结&#34;&gt;操作系统基础总结&lt;/h1&gt;
&lt;h2 id=&#34;操作系统发基本概念&#34;&gt;操作系统发基本概念&lt;/h2&gt;
&lt;h3 id=&#34;什么是操作系统&#34;&gt;什么是操作系统&lt;/h3&gt;
&lt;p&gt;操作系统是计算机系统中的一种重要&lt;strong&gt;软件&lt;/strong&gt;，它管理和控制计算机系统中的资源，为用户和其他软件提供服务。操作系统主要负责&lt;strong&gt;内存管理、进程管理、文件系统管理、设备管理&lt;/strong&gt;等方面的工作。&lt;/p&gt;
&lt;h3 id=&#34;内核态和用户态&#34;&gt;内核态和用户态&lt;/h3&gt;
&lt;p&gt;操作系统中，内核态和用户态是两种不同的执行状态，主要区别在于访问系统资源的权限不同。内核态是操作系统核心代码运行的状态，具有访问系统资源的最高权限，包括访问硬件设备和修改操作系统的状态等。而用户态是普通程序的运行状态，只能访问用户空间的资源，无法直接访问内核空间，需要通过系统调用的方式向操作系统发出请求，以获取相关资源。&lt;/p&gt;
&lt;p&gt;根据进程所能访问到的资源的特点，可以依据进程在系统上的运行状态，分为用户态与内核态。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用户态进程只能访问一些用户程序的数据。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;内核态进程几乎可以访问到计算机的任何资源。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们平时运行的程序出于安全考虑，基本都是运行在用户态，他们没有权限调用系统级别的功能。比如说文件管理，进程控制等。而必须要使用到操作系统提供的这些功能时，就需要用到&lt;strong&gt;系统调用&lt;/strong&gt;了。&lt;/p&gt;
&lt;h3 id=&#34;系统调用&#34;&gt;系统调用&lt;/h3&gt;
&lt;p&gt;系统调用是&lt;strong&gt;操作系统提供的一组接口&lt;/strong&gt;，用于让用户程序可以访问操作系统内核中的服务。操作系统提供了多种系统调用，如文件操作、进程管理、网络通信等。用户程序可以通过调用相应的系统调用，向操作系统发出请求，获取相关的服务。&lt;/p&gt;
&lt;p&gt;系统调用的工作原理是，**当用户程序需要访问操作系统内核中的服务时，需要通过特定的指令或者是函数调用，进入内核态执行相应的系统调用操作。**系统调用操作完成后，操作系统再将结果返回用户程序，用户程序继续在用户态执行。&lt;/p&gt;
&lt;p&gt;系统调用的实现方式有两种：一种是软中断，一种是陷阱。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;软中断是指用户程序通过软件指令，向操作系统发出中断请求。操作系统收到请求后，暂停当前进程的执行，转而执行相应的系统调用操作，完成后再返回用户程序。&lt;/li&gt;
&lt;li&gt;陷阱是指用户程序执行到陷阱指令时，CPU会将控制权限转交给操作系统，让操作系统执行相应的系统调用操作。操作系统完成操作后，再将结果返回用户程序，让用户程序继续执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实际的系统中，系统调用的实现方式通常是与硬件的中断机制相结合，通过硬件中断的方式触发系统调用，使用软中断和陷阱来实现系统调用的具体操作。&lt;/p&gt;
&lt;h2 id=&#34;进程与线程&#34;&gt;进程与线程&lt;/h2&gt;
&lt;h3 id=&#34;进程和线程的区别&#34;&gt;进程和线程的区别&lt;/h3&gt;
&lt;p&gt;进程是操作系统中的基本概念，它是指正在运行的程序的实例。进程拥有自己的内存空间、文件句柄、系统资源等。线程是进程的一个执行单元，每个进程中至少有一个线程。线程共享进程的资源，并拥有自己的执行栈和程序计数器。&lt;/p&gt;
&lt;p&gt;进程和线程的主要区别在于，进程是资源分配的基本单位，而线程是CPU调度和执行的基本单位。进程之间相互独立，互不干扰，而线程之间共享进程的资源，因此线程之间的切换开销比进程小，效率更高。&lt;/p&gt;
&lt;h3 id=&#34;进程的5种状态&#34;&gt;进程的5种状态&lt;/h3&gt;
&lt;p&gt;进程的5种状态包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;就绪状态：进程已经准备好被执行，等待CPU分配时间片。&lt;/li&gt;
&lt;li&gt;运行状态：进程正在CPU上执行指令。&lt;/li&gt;
&lt;li&gt;阻塞状态：进程因为某些原因（如等待I/O操作）而暂时停止执行。&lt;/li&gt;
&lt;li&gt;创建状态：操作系统正在创建新进程。&lt;/li&gt;
&lt;li&gt;终止状态：进程已经完成执行或因为某些原因被中止。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;进程间的通信方式&#34;&gt;进程间的通信方式&lt;/h3&gt;
&lt;p&gt;进程间的通信方式主要有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;管道通信：通过创建一个管道实现两个进程间的通信。是一种&lt;strong&gt;半双工&lt;/strong&gt;的通信方式，通常用于父子进程间或者兄弟进程之间的通信。&lt;/li&gt;
&lt;li&gt;有名管道：有名管道不同于匿名管道之处在于它提供了一个路径名与其关联，使得不存在亲缘关系的进程间也可以通过有名管道进行通信。有名管道严格遵循&lt;strong&gt;先进先出(first in first out)&lt;/strong&gt; 。有名管道的名字存放于文件系统中，内容存放于内存中。&lt;/li&gt;
&lt;li&gt;共享内存通信：两个进程共享同一块内存空间，可以直接读写对方进程的内存数据。不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。这是最快的进程间通信方式。&lt;/li&gt;
&lt;li&gt;消息队列通信：消息队列是消息的链表，存放在内存中并由消息队列标识符标识。MQ对比于Pipe的优点在于如下几点。
&lt;ol&gt;
&lt;li&gt;MQ是&lt;strong&gt;双向的&lt;/strong&gt;，双方都可以收发消息，Pipe是单向的。&lt;/li&gt;
&lt;li&gt;MQ可以按&lt;strong&gt;特定的类型进行消息读取&lt;/strong&gt;，Pipe读取顺序必须为先进先出的顺序。&lt;/li&gt;
&lt;li&gt;MQ可以为消息&lt;strong&gt;分配优先级&lt;/strong&gt;，消费者可以按优先级顺序获取消息，Pipe不行。&lt;/li&gt;
&lt;li&gt;MQ可以完成消息的&lt;strong&gt;异步发送&lt;/strong&gt;，Pipe收发消息时是阻塞的。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;信号通信：信号是一种比较复杂的异步通信方式，它是&lt;strong&gt;软件层次上对中断机制的一种模拟&lt;/strong&gt;。信号可以有硬件和软件两个来源，经由操作系统传递，通知接收信号的进程某个事件已经发生。&lt;/li&gt;
&lt;li&gt;Socket通信：主要用于在&lt;strong&gt;客户端进程和服务器进程之间通过网络进行通信。&lt;/strong&gt; 套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;线程间的同步方式&#34;&gt;线程间的同步方式&lt;/h3&gt;
&lt;p&gt;线程同步适用于多个共享关键资源的线程并发执行，同步线程可以避免关键资源使用的冲突。线程间的同步方式主要有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;互斥锁（Mute）：通过加锁的方式保证同一时间只能有一个线程访问共享资源，只有持有互斥对象的线程才可以访问共享资源，而互斥对象只有一个，所以可以保证共享资源同一时间内最多被一个线程访问。&lt;/li&gt;
&lt;li&gt;信号量（Semaphores）：用于控制多个线程对共享资源的访问，通过信号量的值来判断是否可以访问共享资源。在信号量有余粮的前提下，可以允许多个线程在同一时刻访问同一共享资源。&lt;/li&gt;
&lt;li&gt;事件（Event）：线程间可以通过事件来互相通知，即所谓的 Wait / Notify 操作，通过线程之间相互通知的方式保持线程同步。&lt;/li&gt;
&lt;li&gt;临界区：通过将共享资源保护在临界区内，使得只能有一个线程同时进入临界区，其他线程需要等待。实际上也是一种互斥锁的实现。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;进程调度算法&#34;&gt;进程调度算法&lt;/h3&gt;
&lt;p&gt;进程调度算法有多种，其中比较常见的有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先来先服务调度算法（FCFS）：按照进程到达的顺序进行调度，先到达的进程先执行。&lt;/li&gt;
&lt;li&gt;短作业优先调度算法（SJF）：按照进程需要的执行时间进行排序，执行时间短的进程先执行。&lt;/li&gt;
&lt;li&gt;优先级调度算法：为每个进程赋予一个优先级，优先级高的进程先执行。&lt;/li&gt;
&lt;li&gt;时间片轮转调度算法：为每个进程分配一个时间片，当时间片用完后，就停止当前进程的执行，将CPU分配给下一个进程。&lt;/li&gt;
&lt;li&gt;多级反馈队列调度算法：将进程划分为多个队列，每个队列有不同的时间片大小和优先级，进程开始在第一个队列中运行，如果用完了时间片仍然没有执行完，则被移动到下一个队列，直到执行完毕。多级反馈队列调度算法通过一些反馈机制，可以保证高优先级的作业得到响应，又能使得短作业迅速完成，目前被公认为较好的一种调度算法。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;多级反馈队列调度算法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多级反馈队列调度算法是一种比较流行的调度算法，其主要思想是根据进程的优先级和使用的时间片大小来决定调度顺序。多级反馈队列调度算法将进程划分为多个队列，每个队列具有不同的时间片大小和优先级，首先进入第一级队列中的进程具有最高的优先级，并拥有最小的时间片大小，如果在这个时间片内没有执行完毕，则将其移动到下一个优先级更低的队列中，以便其他进程有机会运行。每个队列中的时间片大小越来越大，优先级越来越低，因此在队列层次结构中，出现相应的优先级和时间片大小的变化。&lt;/p&gt;
&lt;p&gt;多级反馈队列调度算法的优点在于可以确保高优先级的进程优先运行，并且可以提高系统的响应性能。但是，该算法也存在着一些问题，如时间片大小的选择可能会影响系统的性能和响应时间，因此需要根据不同的应用场景进行调整。此外，该算法的实现也比较复杂，需要考虑多个队列之间的切换以及进程的状态转换等问题。&lt;/p&gt;
&lt;p&gt;总的来说，多级反馈队列调度算法是一种灵活性较强的调度算法，可以根据不同的应用场景进行调整，以便更好地满足系统的需求。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;死锁&#34;&gt;死锁&lt;/h2&gt;
&lt;p&gt;死锁是指两个或多个进程在执行过程中，因争夺资源而造成的一种相互等待的现象，若无外力作用，这些进程都将无法向前推进。简单来说，死锁是由于两个或多个进程都在等待系统中的某个资源而造成的一种僵局，这些进程都无法继续执行，并且也无法释放已经占有的资源。死锁的发生可能会导致系统崩溃，因此必须采取措施避免死锁的发生。&lt;/p&gt;
&lt;h3 id=&#34;死锁产生的四个条件&#34;&gt;死锁产生的四个条件&lt;/h3&gt;
&lt;p&gt;死锁产生的四个必要条件包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;互斥条件：**资源不能被共享，只有一个进程能够占用，**其它进程申请该资源，必须等待直到资源释放。&lt;/li&gt;
&lt;li&gt;请求与保持条件：已经占用资源的进程可以&lt;strong&gt;继续请求其他资源而不释放已占有的资源&lt;/strong&gt;，即使该进程请求资源而阻塞时，对已获得的资源也不会释放。&lt;/li&gt;
&lt;li&gt;非抢占条件：已经分配的&lt;strong&gt;资源不能被剥夺&lt;/strong&gt;，只能由占有资源的进程自己释放。&lt;/li&gt;
&lt;li&gt;循环等待条件：多个进程之间形成&lt;strong&gt;头尾相连的循环等待资源关系&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;四个条件需要同时满足时，才有可能发生死锁。&lt;/p&gt;
&lt;h3 id=&#34;解决死锁的四种方法&#34;&gt;解决死锁的四种方法&lt;/h3&gt;
&lt;p&gt;解决死锁的方法可以从&lt;strong&gt;预防&lt;/strong&gt;，&lt;strong&gt;避免&lt;/strong&gt;，&lt;strong&gt;检测&lt;/strong&gt;以及&lt;strong&gt;解除&lt;/strong&gt;这四个角度分析。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;预防死锁：针对死锁产生的四个条件，采取相应的预防措施，以避免死锁的发生。&lt;/li&gt;
&lt;li&gt;避免死锁：在资源分配之前，对资源的请求进行预判，只分配不会导致死锁的资源请求。&lt;/li&gt;
&lt;li&gt;检测死锁：通过检测算法，检测系统中是否存在死锁，如果发现死锁，则采取相应的措施打破死锁。&lt;/li&gt;
&lt;li&gt;解除死锁：采用撤销进程、资源抢占等方法，打破死锁循环等待条件。其中，撤销进程和资源抢占是比较有效的解除死锁方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;死锁的预防&#34;&gt;死锁的预防&lt;/h3&gt;
&lt;p&gt;死锁预防聚焦于破坏四个必要条件中任意一个，就可以预防死锁发生。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;破坏&lt;strong&gt;第一个条件（互斥条件）：使得资源可以同时访问。最简单，但很多资源的特性，以及一些线程同步问题导致其并不能同时访问。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;破坏&lt;strong&gt;第三个条件（非抢占）：采用剥夺式的调度算法，但一般只适用于主存和CPU资源的分配，不适合所有的资源，而且可能会导致资源利用率下降。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上两种方法因为自身的一些缺陷不太实用，一般比较实用的预防方法，是考虑破坏&lt;strong&gt;第二个和第四个条件&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;破坏&lt;strong&gt;第二个条件（请求并保持）：静态分配策略&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;静态分配策略&lt;/strong&gt;破坏了死锁产生的第二个条件。一个进程开始执行前，就提前申请到它执行过程中所需要用到的所有资源。进程要么占有其所需要的所有资源后开始执行，要么不占有任何资源并不执行，就不会出现持有一些资源而等待另一些资源的情况。&lt;/p&gt;
&lt;p&gt;静态分配策略逻辑和实现都很简单，但缺点是&lt;strong&gt;严重降低了资源利用率&lt;/strong&gt;。一个进程需要的资源中有些可能只会使用非常短的时间然后闲置，或者说是额外情况下才会使用的，这就导致了进程占用一些&lt;strong&gt;本身很少用到的资源&lt;/strong&gt;，其它进程需要等待的情况，降低了系统的并发性能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;第四个条件（循环等待）：层次分配策略&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;层次分配策略&lt;/strong&gt;破坏了死锁产生的第四个条件。层次分配策略将所有资源分成多个层次，一个进程得到一个资源后，&lt;strong&gt;只能再申请较高一层的资源&lt;/strong&gt;；而当进程要释放一个资源时，同时也要先释放占用的较高层的资源。通过预定义的资源申请层次，可以避免出现循环等待链。&lt;/p&gt;
&lt;h3 id=&#34;死锁的避免&#34;&gt;死锁的避免&lt;/h3&gt;
&lt;p&gt;死锁的预防的思想是破坏死锁的四个必要条件之一就可以预防系统发生死锁。但会导致&lt;strong&gt;资源利用率较低&lt;/strong&gt;以及&lt;strong&gt;进程并发度不高&lt;/strong&gt;等问题。而死锁的避免则允许系统中存在四个必要条件，关键在于掌握并发进程中资源申请和分配情况，作出合理的选择，同样能避免发生死锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;银行家算法&lt;/strong&gt;：系统的状态可以分为&lt;strong&gt;安全状态&lt;/strong&gt;和&lt;strong&gt;不安全状态&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;安全状态：OS 可以保证所有的进程在有限时间内能得到各自所需要的全部资源，系统处于安全状态，此时不会发生死锁。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不安全状态：与安全状态相反，可能会发生死锁。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每当需要为进程分配资源时，会通过&lt;strong&gt;银行家算法&lt;/strong&gt;先&lt;strong&gt;试探为该进程分配资源&lt;/strong&gt;，然后通过&lt;strong&gt;安全性算法&lt;/strong&gt;判断&lt;strong&gt;分配资源后系统是否处于安全状态&lt;/strong&gt;，如果不安全则不进行分配，进程继续等待，若还能处于安全状态，则分配资源给进程。&lt;/p&gt;
&lt;p&gt;死锁的避免可以解决&lt;strong&gt;资源利用率低&lt;/strong&gt;的问题，但需要不断检测每个进程对各类资源占用和申请情况，以及做&lt;strong&gt;安全性检测&lt;/strong&gt;，也需要耗费较多额外的效率。&lt;/p&gt;
&lt;h3 id=&#34;死锁的检测--死锁的解除&#34;&gt;死锁的检测 &amp;amp; 死锁的解除&lt;/h3&gt;
&lt;p&gt;对资源分配加以限制可以&lt;strong&gt;预防或避免&lt;/strong&gt;死锁发生，但都不利于&lt;strong&gt;系统资源的充分共享&lt;/strong&gt;。另一条途径是采用**死锁的检测与解除：*&lt;em&gt;对资源分配不作任何限制，不避免死锁的产生。系统*&lt;em&gt;定期会执行一个“死锁检测”程序&lt;/em&gt;&lt;/em&gt;，判断是否出现死锁，如检测出现死锁再加以解除。&lt;/p&gt;
&lt;p&gt;死锁的检测依据&lt;strong&gt;进程-资源分配图&lt;/strong&gt;，OS 中每一时刻的&lt;strong&gt;系统状态&lt;/strong&gt;都可以使用该图来表示，这是一种&lt;strong&gt;描述进程对资源申请以及分配关系的一种有向图&lt;/strong&gt;，可以用于检测系统是否处于死锁状态。&lt;/p&gt;
&lt;p&gt;当检测到存在死锁时，应设法让其解除。通常有以下四种方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;结束所有进程的执行，重启 OS：简单粗暴，但未保存的所有进度会丢失，损失巨大。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;撤销涉及死锁的所有进程，解除死锁后继续运行：可以打破死锁的循环等待条件，但代价也很大，某些进程已经计算很长时间，撤销后使得之前的计算也浪费了。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;逐个撤销涉及死锁的进程，回收资源直到死锁解除：相较于上一种方法更为温和，很多情况下只要撤销部分进程后，死锁就得以解除，剩余进程可以继续运行。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抢占资源：从涉及死锁的进程中抢占资源，夺得资源再分配给涉及死锁的进程直到解除死锁。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;内存管理&#34;&gt;内存管理&lt;/h2&gt;
&lt;h3 id=&#34;操作系统内存管理的作用&#34;&gt;操作系统内存管理的作用&lt;/h3&gt;
&lt;p&gt;操作系统内存管理的作用是为了让多个进程可以同时运行，并且不会相互干扰。内存管理的主要任务包括&lt;strong&gt;内存分配和内存回收&lt;/strong&gt;。内存分配是指为进程分配内存空间，而内存回收是指释放进程占用的内存空间。操作系统需要实现&lt;strong&gt;虚拟内存、页面置换、内存保护&lt;/strong&gt;等功能，以确保系统运行的稳定性和安全性。&lt;/p&gt;
&lt;h3 id=&#34;内存管理机制&#34;&gt;内存管理机制&lt;/h3&gt;
&lt;p&gt;内存的管理机制可以简单分为&lt;strong&gt;连续分配管理方式&lt;/strong&gt;和&lt;strong&gt;非连续分配管理&lt;/strong&gt;方式这两种管理机制。连续分配管理方式是指为一个用户程序分配一块连续的内存空间，常见的如&lt;strong&gt;块式内存管理&lt;/strong&gt;。非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的物理内存中，常见的如&lt;strong&gt;页式内存管理&lt;/strong&gt;和&lt;strong&gt;段式内存管理&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;块式内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;块式内存管理是一种最早期的内存管理方式，主要应用于早期计算机操作系统中。该方法将内存划分为固定大小的块，每个块中只包含一个进程，不同进程之间的内存空间是独立的。如果程序需要更多的内存，操作系统将分配给它一个块，如果程序需要的内存很小，那么分配给它的块就会浪费一部分内存，这些未被利用的空间被称为碎片。&lt;/p&gt;
&lt;p&gt;块式内存管理的优点是实现简单，易于操作和维护。而且，这种方法在早期计算机硬件资源受限的情况下，可以有效地利用内存。然而，块式内存管理也存在一些缺点，其中最大的缺点就是&lt;strong&gt;内存浪费问题。如果程序只需要很少的内存空间，那么它将占用整个块，即使其中大部分空间是未被利用的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;页式内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页式内存管理是一种采用固定大小的页面来划分内存空间的管理方式。在页式内存管理中，物理内存空间被划分为固定大小的块，每一块被称为一页，而逻辑内存空间也被划分为固定大小的块，每一块被称为一个页面。当一个进程需要使用内存时，&lt;strong&gt;操作系统将为其分配一个或多个页面，当进程访问某个页面时，操作系统通过页面映射机制将逻辑地址转换为物理地址，以实现对内存的访问。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页式内存管理的优点是&lt;strong&gt;可以有效地解决内存浪费问题&lt;/strong&gt;，因为它可以动态地分配内存空间，精确地满足进程的内存需求。此外，页式内存管理还可以实现内存保护和共享，提高系统的稳定性和安全性。缺点是在&lt;strong&gt;页面置换时可能会出现性能问题&lt;/strong&gt;，因为页面置换需要将页面从磁盘中读入内存，这可能会影响系统的性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段式内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。段式内存管理是一种较为复杂的内存管理方式，**段式管理把主存分为一段段的，段是有实际意义的，**每个段具有不同的长度和访问权限，而不是像页式内存管理那样划分为固定大小的块。例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。&lt;/p&gt;
&lt;p&gt;简单来说：&lt;strong&gt;页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段页式内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段页式管理机制结合了段式管理和页式管理的优点&lt;/strong&gt;。段页式管理机制把内存先分成若干段，每个段又分成若干页，也就是说段页式管理机制中段与段之间以及段的内部的都是离散的。&lt;strong&gt;既可以实现内存的动态分配，又可以满足不同进程对内存空间的需求。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;分页机制和分段机制的区别与共同点&#34;&gt;分页机制和分段机制的区别与共同点&lt;/h3&gt;
&lt;p&gt;分页机制和分段机制都是&lt;strong&gt;内存离散管理&lt;/strong&gt;的方式，其中分页机制是将&lt;strong&gt;物理内存划分为大小相等的页框，将逻辑地址划分为大小相等的页&lt;/strong&gt;；而分段机制是将&lt;strong&gt;逻辑地址划分为大小不等、具有不同含义的段，每个段可以动态地分配不同大小的内存空间。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;它们的区别在于，**分页机制中页是物理单位，是操作系统管理内存的基本单位，*&lt;em&gt;每个页都有相同的大小；而*&lt;em&gt;分段机制中段是逻辑单位，是用户程序管理内存的基本单位，每个段具有不同的大小和含义。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;物理地址与虚拟地址逻辑地址虚拟内存&#34;&gt;物理地址与虚拟地址（逻辑地址/虚拟内存）&lt;/h3&gt;
&lt;p&gt;物理地址，即计算机硬件中内存的真正编址。而所谓虚拟地址，即操作系统将实际的物理物理地址抽象为范围更大的一个地址空间给予进程使用，进程所能看到的地址空间都是虚拟地址。&lt;/p&gt;
&lt;p&gt;我们编程一般只有可能和虚拟地址打交道，比如在C语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的虚拟地址，虚拟地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。虚拟&lt;strong&gt;地址由操作系统统一管理物理内存分配，使得程序更具有安全性。操作系统如何从虚拟地址定位到实际的物理地址，则需要通过页表的帮助。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;cpu如何寻址&#34;&gt;CPU如何寻址&lt;/h3&gt;
&lt;p&gt;所谓的 CPU 寻址，就是通过 CPU 完成虚拟地址到物理地址的转换。&lt;/p&gt;
&lt;p&gt;现代处理器使用的是一种称为 &lt;strong&gt;虚拟寻址(Virtual Addressing)&lt;/strong&gt; 的寻址方式。&lt;strong&gt;使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。&lt;/strong&gt; 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 &lt;strong&gt;内存管理单元（Memory Management Unit, MMU）&lt;/strong&gt; 的硬件。&lt;/p&gt;
&lt;p&gt;以下来源于：&lt;a class=&#34;link&#34; href=&#34;https://www.zhihu.com/question/63375062/answer/1403291487&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;操作系统中的多级页表到底是为了解决什么问题？ - axiqia的回答 - 知乎&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一般来说，任何进程切换都会暗示着更换活动页表集。Linux内核为每一个进程维护一个task_struct结构体（即进程描述符PCB），task_struct-&amp;gt;mm_struct结构体成员用来保存该进程的页表。**在进程切换的过程中，内核把新的页表的地址写入CR3控制寄存器。**CR3中含有页目录表的物理内存基地址，因此该寄存器也被称为页目录基地址寄存器PDBR（Page-Directory Base address Register）。&lt;/p&gt;
&lt;p&gt;每个处理器core都有一个MMU，包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TLB：是页表的高速缓存，存储着最近转化的一些目录项。&lt;/li&gt;
&lt;li&gt;Table Walk Unit：负责从页表中读取虚拟地址对应的物理地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于每次转换，MMU首先在TLB中检查现有的缓存。如果没有命中，根据CR3寄存器，Table Walk Unit将从内存中的页表查询。&lt;/p&gt;
&lt;h3 id=&#34;虚拟地址空间的意义&#34;&gt;虚拟地址空间的意义&lt;/h3&gt;
&lt;p&gt;没有虚拟地址空间的时候，&lt;strong&gt;程序都是直接访问和操作的都是物理内存&lt;/strong&gt; 。这样会导致一些问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;用户程序可以访问任意内存、寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;地址空间不存在隔离，想要同时运行多个程序特别困难，程序间会对各自的内存空间进行干扰。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;**总结来说：*&lt;em&gt;如果*&lt;em&gt;直接把物理地址暴露出来的话会带来严重问题&lt;/em&gt;&lt;/em&gt;，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。&lt;/p&gt;
&lt;p&gt;通过虚拟地址访问内存有以下优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。对于程序员而言，&lt;strong&gt;看到的都是连续的地址空间，方便程序的编写。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区&lt;/strong&gt;。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;**不同进程使用的虚拟地址彼此隔离。**一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存，为进程并发提供了可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。&lt;/p&gt;
&lt;p&gt;与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。From:&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%e8%99%9a%e6%8b%9f%e5%86%85%e5%ad%98&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zh.wikipedia.org/wiki/虚拟内存&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;快表-tlb&#34;&gt;快表 TLB&lt;/h3&gt;
&lt;p&gt;为了解决虚拟地址到物理地址的转换速度，操作系统在 &lt;strong&gt;页表方案&lt;/strong&gt;基础之上引入了 &lt;strong&gt;快表&lt;/strong&gt;来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的&lt;strong&gt;内容是页表的一部分或者全部内容&lt;/strong&gt;。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于&lt;strong&gt;采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存&lt;/strong&gt;，这样可加速查找并提高指令执行速度。&lt;/p&gt;
&lt;p&gt;使用快表之后的地址转换流程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;根据虚拟地址中的页号查快表；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果该页在快表中，直接从快表中读取相应的物理地址；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。&lt;/p&gt;
&lt;h3 id=&#34;多级页表&#34;&gt;多级页表&lt;/h3&gt;
&lt;p&gt;引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。具体的多级页表如何节省空间，可以见下面这篇文章。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.zhihu.com/question/63375062/answer/1403291487&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;操作系统中的多级页表到底是为了解决什么问题？ - axiqia的回答 - 知乎&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;局部性原理&#34;&gt;局部性原理&lt;/h3&gt;
&lt;p&gt;局部性原理是虚拟内存技术的基础，&lt;strong&gt;正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。”&lt;/p&gt;
&lt;p&gt;局部性原理表现在以下两个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;时间局部性是通过将&lt;strong&gt;近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现&lt;/strong&gt;。空间局部性通常是使&lt;strong&gt;用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;虚拟内存技术实际上就是建立了**“内存一外存”**的两级存储器的结构，利用局部性原理实现髙速缓存。&lt;/p&gt;
&lt;h3 id=&#34;虚拟内存的技术实现&#34;&gt;虚拟内存的技术实现&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。&lt;/strong&gt; 虚拟内存的实现有以下三种方式：&lt;/p&gt;
&lt;p&gt;请求分页存储管理&lt;/p&gt;
&lt;p&gt;请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的&lt;strong&gt;页面置换算法&lt;/strong&gt;将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。&lt;/p&gt;
&lt;p&gt;请求分段存储管理&lt;/p&gt;
&lt;p&gt;请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。&lt;/p&gt;
&lt;p&gt;请求段页式存储管理&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;请求分页管理与分页管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**请求分页存储管理建立在分页管理之上。*&lt;em&gt;他们的根本区别是*&lt;em&gt;是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因&lt;/em&gt;&lt;/em&gt;，我们在上面已经分析过了。&lt;/p&gt;
&lt;p&gt;它们之间的根本区别在于是否将作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚拟内存，而分页存储管理却不能提供虚存。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不管是上面那种实现方式，我们一般都需要&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;**一定容量的内存和外存：**在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；&lt;/li&gt;
&lt;li&gt;**缺页中断：**如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序；&lt;/li&gt;
&lt;li&gt;**虚拟地址空间 ：**逻辑地址到物理地址的变换。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;页面置换算法&#34;&gt;页面置换算法&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;地址映射&lt;/strong&gt;过程中，若在页面中发现所要访问的页面不在内存中，则发生&lt;strong&gt;缺页中断&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。&lt;strong&gt;用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页面置换算法是在虚拟内存管理中使用的一种算法，用于在缺页中断时选择一个页面进行置换。以下是几种常见的页面置换算法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;最优页面置换算法（OPT）：&lt;/strong&gt; 选择在未来最长时间内不会使用的页面进行置换。但是，这种算法需要预测未来的行为，当前技术能力下实际上并没有被广泛使用，一般作为衡量其他置换算法的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;先进先出页面置换算法（FIFO）：&lt;/strong&gt; 选择最早进入内存的页面进行置换。这种算法很简单，但是它没有考虑到页面的重要性和使用频率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最近最少使用页面置换算法（LRU）：&lt;/strong&gt; 选择最近最少使用的页面进行置换。这种算法需要记录页面&lt;strong&gt;最近一次被使用的时间&lt;/strong&gt;，并在缺页中断时选择最久未使用的页面进行置换。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时钟页面置换算法（Clock）：&lt;/strong&gt; 在一张环形链表上维护页面，用一个指针指向当前扫描到的页面。当需要置换页面时，如果指针当前指向的页面被使用过，则将其修改为“未使用过”状态，并将指针向后移动；否则，选择该页面进行置换。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最不常用页面置换算法（LFU）：&lt;/strong&gt; 选择最近使用次数最少的页面进行置换。这种算法需要记录每个&lt;strong&gt;页面被访问的次数&lt;/strong&gt;，并在缺页中断时选择最少使用的页面进行置换。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总体而言，不同的页面置换算法适用于不同的场景和应用程序，需要根据具体情况选择合适的算法进行使用。&lt;/p&gt;
&lt;h2 id=&#34;cpu&#34;&gt;CPU&lt;/h2&gt;
&lt;h3 id=&#34;cpu-调度算法&#34;&gt;CPU 调度算法&lt;/h3&gt;
&lt;p&gt;操作系统中的 CPU 调度算法主要有以下几种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;先来先服务（FCFS）：&lt;/strong&gt; 采用先到先服务的原则，按照作业进入队列的先后顺序进行调度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;短作业优先（SJF）：&lt;/strong&gt; 采用先到先服务的原则，但是优先选择执行时间短的作业。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高优先级优先（HPF）：&lt;/strong&gt; 采用抢占式调度，根据作业的优先级进行调度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时间片轮转（RR）：&lt;/strong&gt; 每个作业被分配一个时间片，当时间片用完后，操作系统会调度下一个作业执行。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些调度算法各有优劣，没有银弹，只能根据具体场景选择具体的调度算法。因此，&lt;strong&gt;多级队列调度&lt;/strong&gt; （Multilevel Queue） 就诞生了。简单来说就是把&lt;strong&gt;就绪队列（存放待执行进程）分成多个独立队列，每个队列都有自己的调度算法。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;多级队列调度&#34;&gt;多级队列调度&lt;/h3&gt;
&lt;p&gt;多级队列调度（Multilevel Queue）是一种操作系统中的 CPU 调度算法，是先将就绪队列（存放待执行进程）分成多个独立队列，每个队列都有自己的调度算法。通常情况下，将进程分为几个不同的等级，每个等级会使用不同的调度算法，以保证不同等级的进程有不同的处理优先级。多级队列调度可以根据具体场景选择具体的调度算法。&lt;/p&gt;
&lt;p&gt;多级队列调度的实现原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;将进程分为不同的等级&lt;/strong&gt;。通常情况下，将进程分为多个等级，每个等级都有不同的处理优先级。例如，将进程分为高、中、低三个等级，高优先级的进程会被优先执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为每个等级分配一个独立的就绪队列&lt;/strong&gt;。每个队列都有自己的调度算法，例如，高优先级的队列使用高优先级优先（HPF）算法，中优先级的队列使用时间片轮转（RR）算法，低优先级的队列使用先来先服务（FCFS）算法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按照进程的优先级将进程放入相应的队列中&lt;/strong&gt;。例如，高优先级的进程会放入高优先级队列中，低优先级的进程会放入低优先级队列中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;按照队列的优先级依次调度进程&lt;/strong&gt;。在多级队列调度中，高优先级队列的进程总是先于低优先级队列的进程被调度。在每个队列中，根据相应的调度算法，依次调度进程。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总之，多级队列调度是一种非常灵活的调度算法，可以根据具体场景选择不同的调度算法和队列数量。它可以保证优先级高的进程优先执行，同时可以避免低优先级进程长时间得不到执行的情况。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
